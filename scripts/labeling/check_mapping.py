import json
from collections import Counter, defaultdict
import os

"""
ë©”íƒ€ë°ì´í„° í†µê³„ ë¶„ì„ ë° ë¼ë²¨ ë§¤í•‘ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Train/Valid ë°ì´í„°ì…‹ì˜ ë©”íƒ€ë°ì´í„° ë¶„í¬ë¥¼ ë¶„ì„í•˜ê³  ë¬´ê²°ì„±ì„ ê²€ì‚¬í•©ë‹ˆë‹¤.
ì£¼ìš” ê¸°ëŠ¥:
1. ê° í•„ë“œ(Fashion Style, Vibe, Shot Type)ë³„ í´ë˜ìŠ¤ ë¶„í¬ ì¶œë ¥.
2. Train ë°ì´í„° ë¶€ì¡±(Low Data) ë° Valid Only(Unseen in Train) í´ë˜ìŠ¤ ê°ì§€.
3. `fashion_style`ì— ëŒ€í•œ ë¼ë²¨ ë§¤í•‘ íŒŒì¼(`label_mapping.json`) ìƒì„±.

ì‚¬ìš©ë²•:
    python check_mapping.py [train_file] [valid_file]
"""

def check_all_statistics(train_file, valid_file):
    print(f"ğŸ” ì „ì²´ ë©”íƒ€ë°ì´í„°(Style, Vibe, Shot) í†µê³„ ë¶„ì„ ì‹œì‘...\n")

    if not os.path.exists(train_file) or not os.path.exists(valid_file):
        print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ë¶„ì„í•  íƒ€ê²Ÿ í•„ë“œ ì •ì˜
    target_fields = ['fashion_style', 'vibe_category', 'shot_type']
    
    # ë°ì´í„° ë‹´ì„ êµ¬ì¡°: stats[field_name][train_or_valid] = [list of values]
    stats = {field: {'train': [], 'valid': []} for field in target_fields}

    def load_data(filename, split_name):
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        try:
                            data = json.loads(line)
                            meta = data.get('image_metadata', {})
                            
                            for field in target_fields:
                                value = meta.get(field)
                                if value:
                                    stats[field][split_name].append(value)
                        except: continue
        except Exception as e:
            print(f"âš ï¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({filename}): {e}")

    # ë°ì´í„° ë¡œë“œ
    load_data(train_file, 'train')
    load_data(valid_file, 'valid')

    # === ë¶„ì„ ë° ì¶œë ¥ ë£¨í”„ ===
    for field in target_fields:
        print(f"\n{'='*20} [ {field.upper()} ] ë¶„ì„ ê²°ê³¼ {'='*20}")
        
        t_counter = Counter(stats[field]['train'])
        v_counter = Counter(stats[field]['valid'])
        
        all_classes = sorted(list(set(t_counter.keys()) | set(v_counter.keys())))
        
        print(f"{'Class Name':<30} | {'Train':<8} | {'Valid':<8} | {'Status'}")
        print("-" * 70)

        min_k = 4
        
        for cls in all_classes:
            t_cnt = t_counter.get(cls, 0)
            v_cnt = v_counter.get(cls, 0)
            
            status = ""
            
            # 1. Train ë°ì´í„° ë¶€ì¡± ì²´í¬
            if t_cnt < min_k:
                if field == 'fashion_style':
                    status = "ğŸš¨ CRITICAL (Sampler Error)"
                else:
                    status = "âš ï¸ Warning (Low Data)"
            
            # 2. Valid Only ì²´í¬ (í•™ìŠµ ì•ˆ ë¨)
            if t_cnt == 0 and v_cnt > 0:
                status = "âŒ Unseen in Train"

            print(f"{cls:<30} | {t_cnt:<8} | {v_cnt:<8} | {status}")

        print("-" * 70)
        print(f"Total Count: {len(stats[field]['train'])} (Train) / {len(stats[field]['valid'])} (Valid)")
        
import json
from collections import Counter, defaultdict
import os
import sys

def check_all_statistics(train_file, valid_file):
    output_lines = []
    output_lines.append(f"ğŸ” ì „ì²´ ë©”íƒ€ë°ì´í„°(Style, Vibe, Shot) í†µê³„ ë¶„ì„ ì‹œì‘...\n")
    output_lines.append(f"ğŸ“‚ Train File: {train_file}")
    output_lines.append(f"ğŸ“‚ Valid File: {valid_file}")

    if not os.path.exists(train_file) or not os.path.exists(valid_file):
        print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ë¶„ì„í•  íƒ€ê²Ÿ í•„ë“œ ì •ì˜
    target_fields = ['fashion_style', 'vibe_category', 'shot_type']
    
    # ë°ì´í„° ë‹´ì„ êµ¬ì¡°: stats[field_name][train_or_valid] = [list of values]
    stats = {field: {'train': [], 'valid': []} for field in target_fields}

    def load_data(filename, split_name):
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        try:
                            data = json.loads(line)
                            meta = data.get('image_metadata', {})
                            
                            for field in target_fields:
                                value = meta.get(field)
                                if value:
                                    stats[field][split_name].append(value)
                        except: continue
        except Exception as e:
            output_lines.append(f"âš ï¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({filename}): {e}")

    # ë°ì´í„° ë¡œë“œ
    load_data(train_file, 'train')
    load_data(valid_file, 'valid')

    # === ë¶„ì„ ë° ì¶œë ¥ ë£¨í”„ ===
    for field in target_fields:
        output_lines.append(f"\n{'='*20} [ {field.upper()} ] ë¶„ì„ ê²°ê³¼ {'='*20}")
        
        t_counter = Counter(stats[field]['train'])
        v_counter = Counter(stats[field]['valid'])
        
        all_classes = sorted(list(set(t_counter.keys()) | set(v_counter.keys())))
        
        output_lines.append(f"{'Class Name':<30} | {'Train':<8} | {'Valid':<8} | {'Status'}")
        output_lines.append("-" * 70)

        min_k = 4
        
        for cls in all_classes:
            t_cnt = t_counter.get(cls, 0)
            v_cnt = v_counter.get(cls, 0)
            
            status = ""
            
            # 1. Train ë°ì´í„° ë¶€ì¡± ì²´í¬
            if t_cnt < min_k:
                if field == 'fashion_style':
                    status = "ğŸš¨ CRITICAL (Sampler Error)"
                else:
                    status = "âš ï¸ Warning (Low Data)"
            
            # 2. Valid Only ì²´í¬ (í•™ìŠµ ì•ˆ ë¨)
            if t_cnt == 0 and v_cnt > 0:
                status = "âŒ Unseen in Train"

            output_lines.append(f"{cls:<30} | {t_cnt:<8} | {v_cnt:<8} | {status}")

        output_lines.append("-" * 70)
        output_lines.append(f"Total Count: {len(stats[field]['train'])} (Train) / {len(stats[field]['valid'])} (Valid)")
        
        # Mapping íŒŒì¼ ì €ì¥
        if field == 'fashion_style':
            mapping = {name: i for i, name in enumerate(all_classes)}
            with open('label_mapping.json', 'w') as f:
                json.dump(mapping, f, indent=4)
            output_lines.append(f"ğŸ’¾ [fashion_style] ë§¤í•‘ íŒŒì¼ ì €ì¥ë¨: label_mapping.json")

    # Print and Save
import json
from collections import Counter, defaultdict
import os
import sys

def check_all_statistics(train_file, valid_file):
    output_lines = []
    output_lines.append(f"ğŸ” ì „ì²´ ë©”íƒ€ë°ì´í„°(Style, Vibe, Shot) í†µê³„ ë¶„ì„ ì‹œì‘...\n")
    output_lines.append(f"ğŸ“‚ Train File: {train_file}")
    output_lines.append(f"ğŸ“‚ Valid File: {valid_file}")

    if not os.path.exists(train_file) or not os.path.exists(valid_file):
        print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ë¶„ì„í•  íƒ€ê²Ÿ í•„ë“œ ì •ì˜
    target_fields = ['fashion_style', 'vibe_category', 'shot_type']
    
    # ë°ì´í„° ë‹´ì„ êµ¬ì¡°: stats[field_name][train_or_valid] = [list of values]
    stats = {field: {'train': [], 'valid': []} for field in target_fields}

    def load_data(filename, split_name):
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        try:
                            data = json.loads(line)
                            meta = data.get('image_metadata', {})
                            
                            for field in target_fields:
                                value = meta.get(field)
                                if value:
                                    stats[field][split_name].append(value)
                        except: continue
        except Exception as e:
            output_lines.append(f"âš ï¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({filename}): {e}")

    # ë°ì´í„° ë¡œë“œ
    load_data(train_file, 'train')
    load_data(valid_file, 'valid')

    # === ë¶„ì„ ë° ì¶œë ¥ ë£¨í”„ ===
    for field in target_fields:
        output_lines.append(f"\n{'='*20} [ {field.upper()} ] ë¶„ì„ ê²°ê³¼ {'='*20}")
        
        t_counter = Counter(stats[field]['train'])
        v_counter = Counter(stats[field]['valid'])
        
        all_classes = sorted(list(set(t_counter.keys()) | set(v_counter.keys())))
        
        output_lines.append(f"{'Class Name':<30} | {'Train':<8} | {'Valid':<8} | {'Status'}")
        output_lines.append("-" * 70)

        min_k = 4
        
        for cls in all_classes:
            t_cnt = t_counter.get(cls, 0)
            v_cnt = v_counter.get(cls, 0)
            
            status = ""
            
            # 1. Train ë°ì´í„° ë¶€ì¡± ì²´í¬
            if t_cnt < min_k:
                if field == 'fashion_style':
                    status = "ğŸš¨ CRITICAL (Sampler Error)"
                else:
                    status = "âš ï¸ Warning (Low Data)"
            
            # 2. Valid Only ì²´í¬ (í•™ìŠµ ì•ˆ ë¨)
            if t_cnt == 0 and v_cnt > 0:
                status = "âŒ Unseen in Train"

            output_lines.append(f"{cls:<30} | {t_cnt:<8} | {v_cnt:<8} | {status}")

        output_lines.append("-" * 70)
        output_lines.append(f"Total Count: {len(stats[field]['train'])} (Train) / {len(stats[field]['valid'])} (Valid)")
        
        # Mapping íŒŒì¼ ì €ì¥
        if field == 'fashion_style':
            mapping = {name: i for i, name in enumerate(all_classes)}
            with open('label_mapping.json', 'w') as f:
                json.dump(mapping, f, indent=4)
            output_lines.append(f"ğŸ’¾ [fashion_style] ë§¤í•‘ íŒŒì¼ ì €ì¥ë¨: label_mapping.json")

    # Print and Save
    full_report = '\n'.join(output_lines)
    print(full_report)
    with open('report.txt', 'w', encoding='utf-8') as f:
        f.write(full_report)

if __name__ == "__main__":
    train_file = sys.argv[1] if len(sys.argv) > 1 else 'train_aug_final.jsonl'
    valid_file = sys.argv[2] if len(sys.argv) > 2 else 'train_valid_final.jsonl'
    check_all_statistics(train_file, valid_file)