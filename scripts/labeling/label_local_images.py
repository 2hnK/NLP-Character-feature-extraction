"""
ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ Gemini ë¼ë²¨ë§ ìŠ¤í¬ë¦½íŠ¸

ë¡œì»¬ í´ë”ì˜ ì´ë¯¸ì§€ë“¤ì„ Gemini APIë¡œ ë¼ë²¨ë§í•˜ì—¬ JSONL íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
í•™ìŠµì— ì‚¬ìš©ëœ 5ê°€ì§€ fashion_style ë¶„ë¥˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    set GOOGLE_API_KEY=your_api_key
    python scripts/labeling/label_local_images.py
"""

import os
import json
import time
from pathlib import Path
from PIL import Image
from tqdm import tqdm
from dataclasses import dataclass, asdict
from dotenv import load_dotenv

import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# í•™ìŠµì— ì‚¬ìš©ëœ 5ê°€ì§€ fashion_style (label_mapping.jsonê³¼ ì¼ì¹˜)
FASHION_STYLES = [
    "Casual_Basic",
    "Street_Hip", 
    "Sporty_Athleisure",
    "Chic_Modern",
    "Classy_Elegant"
]

SYSTEM_PROMPT = f"""
Role: Expert Fashion & Social Profile Analyst for Dating Apps.
Output Language: ENGLISH ONLY.

Task: Extract structured metadata from the profile image.

--- 1. CATEGORICAL FIELDS (Strict Enums) ---
Choose exactly ONE value for each category based on visual evidence.

A. fashion_style (MUST be exactly one of these):
- "Casual_Basic": Comfortable, t-shirts, jeans, hoodies, relaxed fit.
- "Street_Hip": Oversized, layering, trendy, cargo, hip-hop vibe.
- "Sporty_Athleisure": Gym wear, leggings, jerseys, tracksuits, activewear.
- "Chic_Modern": All-black, leather, sharp, edgy, city vibe, cool.
- "Classy_Elegant": Shirts, slacks, suits, blouses, dresses, coats, neat & formal.

B. shot_type:
- "Selfie_CloseUp": Face-focused selfie (holding camera).
- "Mirrored_Selfie": Full body or half body selfie taken in a mirror.
- "Others_Cam": Shot taken by someone else (candid, portrait, full body).

C. visual_quality:
- "High" (Pro/Studio/Clear), "Medium" (Decent Mobile), "Low" (Blurry/Dark)

--- 2. DESCRIPTIVE FIELDS (Text) ---

D. physical_features (List of Strings):
- List 3-5 distinct visual traits focusing on hair, accessories, and grooming. 
- Examples: "Wavy brown hair", "Rimless glasses", "Drop earrings", "Beanie hat", "Red lipstick".
- Do NOT describe clothing here (already covered in style).

E. caption (String):
- A natural language description (1-2 sentences) summarizing the person's appearance and the scene.
- Used for text-to-image training.

--- Output JSON Format ---
{{
  "fashion_style": "Enum Value (one of: {', '.join(FASHION_STYLES)})",
  "shot_type": "Enum Value",
  "visual_quality": "Enum Value",
  "physical_features": ["trait1", "trait2", ...],
  "caption": "Full sentence description."
}}
"""


@dataclass
class Config:
    """ì„¤ì •"""
    # ì…ë ¥
    image_dir: str = "archive/test_images"  # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ í´ë”
    
    # ì¶œë ¥
    output_jsonl: str = "archive/validation_labeled.jsonl"
    
    # Gemini ì„¤ì •
    model_name: str = "gemini-2.5-flash"
    
    # ì²˜ë¦¬ ì„¤ì •
    delay_between_requests: float = 0.5  # API ìš”ì²­ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)


def process_image(model: genai.GenerativeModel, image_path: Path) -> dict:
    """ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬"""
    try:
        image = Image.open(image_path).convert('RGB')
        
        response = model.generate_content(
            [SYSTEM_PROMPT, image],
            generation_config={"response_mime_type": "application/json"},
            request_options={"timeout": 120},
            safety_settings={
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
            }
        )
        
        metadata = json.loads(response.text)
        
        # fashion_style ê²€ì¦ ë° ìˆ˜ì •
        if metadata.get('fashion_style') not in FASHION_STYLES:
            print(f"  âš ï¸ Invalid fashion_style: {metadata.get('fashion_style')}, defaulting to Casual_Basic")
            metadata['fashion_style'] = 'Casual_Basic'
        
        return metadata
        
    except Exception as e:
        print(f"Error processing {image_path}: {e}")
        return None


def main():
    config = Config()
    
    # API í‚¤ í™•ì¸
    api_key = os.environ.get("GOOGLE_API_KEY")
    if not api_key:
        print("Error: GOOGLE_API_KEY environment variable not set.")
        print("Set it with: set GOOGLE_API_KEY=your_api_key")
        return
    
    # Gemini ì´ˆê¸°í™”
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(config.model_name)
    print(f"âœ… Gemini model loaded: {config.model_name}")
    
    # ì´ë¯¸ì§€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    image_dir = Path(config.image_dir)
    if not image_dir.exists():
        print(f"Error: Image directory not found: {image_dir}")
        return
    
    image_files = sorted(list(image_dir.glob("*.jpg")) + list(image_dir.glob("*.png")))
    print(f"ğŸ“ Found {len(image_files)} images in {image_dir}")
    
    if not image_files:
        print("No images found to process.")
        return
    
    # ê¸°ì¡´ ì²˜ë¦¬ í•­ëª© ë¡œë“œ (ì´ì–´ì„œ ì²˜ë¦¬)
    processed_filenames = set()
    output_path = Path(config.output_jsonl)
    if output_path.exists():
        with open(output_path, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    data = json.loads(line)
                    processed_filenames.add(data.get('filename'))
                except:
                    pass
        print(f"ğŸ“‹ Already processed: {len(processed_filenames)} items")
    
    # ì²˜ë¦¬ ì‹œì‘
    results = []
    errors = []
    
    with open(output_path, 'a', encoding='utf-8') as output_file:
        for image_path in tqdm(image_files, desc="Processing images"):
            filename = image_path.name
            
            # ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª© ê±´ë„ˆë›°ê¸°
            if filename in processed_filenames:
                continue
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            metadata = process_image(model, image_path)
            
            if metadata:
                result = {
                    'id': f"test_{image_path.stem}",
                    'filename': filename,
                    'image_metadata': metadata
                }
                
                # ì¦‰ì‹œ íŒŒì¼ì— ì €ì¥
                output_file.write(json.dumps(result, ensure_ascii=False) + '\n')
                output_file.flush()
                results.append(result)
            else:
                errors.append(filename)
            
            # Rate limiting
            time.sleep(config.delay_between_requests)
    
    # ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*60}")
    print(f"âœ… Processing Complete!")
    print(f"{'='*60}")
    print(f"Total images: {len(image_files)}")
    print(f"Newly processed: {len(results)}")
    print(f"Errors: {len(errors)}")
    print(f"Output saved to: {output_path}")
    
    if errors:
        print(f"\nFailed images: {errors}")
    
    # í´ë˜ìŠ¤ ë¶„í¬ ì¶œë ¥
    if results:
        style_counts = {}
        for r in results:
            style = r['image_metadata'].get('fashion_style', 'Unknown')
            style_counts[style] = style_counts.get(style, 0) + 1
        
        print(f"\nğŸ“Š Class Distribution:")
        for style, count in sorted(style_counts.items()):
            print(f"  - {style}: {count}")


if __name__ == "__main__":
    main()
