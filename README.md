# NLP Character Feature Extraction

> **Qwen3-VL ê¸°ë°˜ ìºë¦­í„° ìŠ¤íƒ€ì¼ íŠ¹ì§• ì¶”ì¶œ ë° Metric Learning í”„ë¡œì íŠ¸**  
> AWS S3 ë°ì´í„°ì™€ Triplet Lossë¥¼ í™œìš©í•˜ì—¬ íŒ¨ì…˜ ìŠ¤íƒ€ì¼/ë¶„ìœ„ê¸° ê¸°ë°˜ì˜ ì„ë² ë”© ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.

---

## ğŸ“‹ ëª©ì°¨

- [í”„ë¡œì íŠ¸ ê°œìš”](#-í”„ë¡œì íŠ¸-ê°œìš”)
- [ì£¼ìš” ê¸°ëŠ¥](#-ì£¼ìš”-ê¸°ëŠ¥)
- [ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì •](#-ì„¤ì¹˜-ë°-í™˜ê²½-ì„¤ì •)
- [ë°ì´í„° ì¤€ë¹„](#-ë°ì´í„°-ì¤€ë¹„)
- [í•™ìŠµ ì‹¤í–‰](#-í•™ìŠµ-ì‹¤í–‰)
- [í”„ë¡œì íŠ¸ êµ¬ì¡°](#-í”„ë¡œì íŠ¸-êµ¬ì¡°)

---

## ğŸš€ í”„ë¡œì íŠ¸ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” **Qwen3-VL** ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì„ ë°±ë³¸ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬, ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ì„¤ëª…ì—ì„œ ìºë¦­í„°ì˜ **íŒ¨ì…˜ ìŠ¤íƒ€ì¼(Fashion Style)** ë° **ë¶„ìœ„ê¸°(Vibe)** íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.  
**Triplet Loss**ì™€ **Online Mining** ê¸°ë²•ì„ ì ìš©í•˜ì—¬, ë™ì¼í•œ ìŠ¤íƒ€ì¼ì„ ê°€ì§„ ì´ë¯¸ì§€ëŠ” ê°€ê¹ê²Œ, ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ì€ ë©€ê²Œ ì„ë² ë”© ê³µê°„ì— ë°°ì¹˜í•˜ë„ë¡ í•™ìŠµí•©ë‹ˆë‹¤.

---

## âœ¨ ì£¼ìš” ê¸°ëŠ¥

1.  **Qwen3-VL Backbone**: ê°•ë ¥í•œ Vision-Language ëª¨ë¸ì„ íŠ¹ì§• ì¶”ì¶œê¸°ë¡œ ì‚¬ìš©.
2.  **Triplet Loss & Online Mining**: `pytorch-metric-learning` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•œ ì•ˆì •ì ì¸ Metric Learning êµ¬í˜„.
3.  **S3 Data Pipeline**: AWS S3ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ë¡œë“œí•˜ê³ , ë¡œì»¬ JSONL ë©”íƒ€ë°ì´í„°ì™€ ì—°ë™.
4.  **Balanced Batch Sampling (PKSampler)**: ê° ë°°ì¹˜ì— $P$ê°œì˜ í´ë˜ìŠ¤ì™€ $K$ê°œì˜ ìƒ˜í”Œì„ ë³´ì¥í•˜ì—¬ í•™ìŠµ ì•ˆì •ì„± í™•ë³´.
5.  **Label Encoding & Text Formatting**: ë¬¸ìì—´ ë¼ë²¨ ìë™ ì¸ì½”ë”© ë° í…ìŠ¤íŠ¸ ì…ë ¥ í¬ë§·íŒ… ì§€ì›.

---

## ğŸ›  ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì •

### í•„ìˆ˜ ìš”êµ¬ ì‚¬í•­
- Python 3.8+
- PyTorch 2.0+
- CUDA (ê¶Œì¥)

### ì„¤ì¹˜
```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url>
cd NLP-Character-feature-extraction

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

---

## ğŸ“Š ë°ì´í„° ì¤€ë¹„

í•™ìŠµì„ ìœ„í•´ì„œëŠ” S3ì— ì €ì¥ëœ ì´ë¯¸ì§€ì™€ ì´ì— ëŒ€ì‘í•˜ëŠ” JSONL ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.

### 1. ë©”íƒ€ë°ì´í„° ì „ì²˜ë¦¬
ì›ë³¸ JSONL íŒŒì¼ì—ëŠ” ì´ë¯¸ì§€ íŒŒì¼ëª…ì´ë‚˜ ì •ìˆ˜í˜• ë¼ë²¨ì´ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•´ ì´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

```bash
python scripts/preprocess_jsonl.py \
    --input enhanced_train_batch_44_94.jsonl \
    --output train_processed.jsonl \
    --mapping_output label_mapping.json
```

- **`--input`**: ì›ë³¸ JSONL íŒŒì¼ ê²½ë¡œ
- **`--output`**: ì „ì²˜ë¦¬ëœ JSONL íŒŒì¼ ì €ì¥ ê²½ë¡œ (íŒŒì¼ëª… `filename` ë° í¬ë§·íŒ…ëœ `text_input` ì¶”ê°€ë¨)
- **`--mapping_output`**: ë¼ë²¨(ìŠ¤íƒ€ì¼)ê³¼ ì •ìˆ˜ ì¸ë±ìŠ¤ ë§¤í•‘ ì •ë³´ ì €ì¥ ê²½ë¡œ

### 2. ìƒì„±ëœ íŒŒì¼ ì˜ˆì‹œ
- **`train_processed.jsonl`**:
  ```json
  {
    "filename": "aug_00000.jpg",
    "image_metadata": { "fashion_style": "Dandy_Minimal", ... },
    "text_input": "Style: Dandy_Minimal. Features: ... Vibe: Warm_Friendly."
  }
  ```
- **`label_mapping.json`**:
  ```json
  {
    "Casual_Basic": 0,
    "Dandy_Minimal": 1,
    ...
  }
  ```

---

## ğŸƒâ€â™‚ï¸ í•™ìŠµ ì‹¤í–‰

ì „ì²˜ë¦¬ëœ ë°ì´í„°ì™€ S3 ë²„í‚· ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.

```bash
python scripts/train.py \
    --jsonl_path train_processed.jsonl \
    --bucket_name sometimes-ki-datasets \
    --prefix "characters/augmented/generated/" \
    --p 8 \
    --k 4 \
    --epochs 10 \
    --lr 1e-5 \
    --margin 0.2
```

### ì£¼ìš” ì¸ì ì„¤ëª…
- **`--jsonl_path`**: ì „ì²˜ë¦¬ëœ ë©”íƒ€ë°ì´í„° íŒŒì¼ ê²½ë¡œ
- **`--bucket_name`**: AWS S3 ë²„í‚· ì´ë¦„
- **`--prefix`**: ì´ë¯¸ì§€ê°€ ì €ì¥ëœ S3 ê²½ë¡œ ì ‘ë‘ì‚¬
- **`--p`**: ë°°ì¹˜ ë‹¹ í´ë˜ìŠ¤(ìŠ¤íƒ€ì¼) ê°œìˆ˜ (ê¸°ë³¸ê°’: 8)
- **`--k`**: í´ë˜ìŠ¤ ë‹¹ ìƒ˜í”Œ ì´ë¯¸ì§€ ê°œìˆ˜ (ê¸°ë³¸ê°’: 4)
  - *Batch Size = P Ã— K*
- **`--margin`**: Triplet Loss ë§ˆì§„ (ê¸°ë³¸ê°’: 0.2)

---

## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
NLP-Character-feature-extraction/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocess_jsonl.py      # ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¼ë²¨ ë§¤í•‘ ìƒì„±
â”‚   â”œâ”€â”€ train.py                 # Triplet Loss í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ test_triplet_components.py # ì»´í¬ë„ŒíŠ¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ README.md                # ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš© ê°€ì´ë“œ
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ s3_dataset.py        # S3 ë°ì´í„°ì…‹ ë° ì´ë¯¸ì§€ ë¡œë”
â”‚   â”‚   â””â”€â”€ sampler.py           # PKSampler (Balanced Batch)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ losses.py            # OnlineTripletLoss ë˜í¼
â”‚   â”‚   â”œâ”€â”€ projection.py        # Projection Head ëª¨ë“ˆ
â”‚   â”‚   â””â”€â”€ qwen_backbone.py     # Qwen3-VL ë°±ë³¸ ëª¨ë¸
â”œâ”€â”€ requirements.txt             # í”„ë¡œì íŠ¸ ì˜ì¡´ì„±
â”œâ”€â”€ label_mapping.json           # (ìƒì„±ë¨) ë¼ë²¨ ë§¤í•‘ íŒŒì¼
â”œâ”€â”€ train_processed.jsonl        # (ìƒì„±ë¨) ì „ì²˜ë¦¬ëœ ë©”íƒ€ë°ì´í„°
â””â”€â”€ README.md                    # ë©”ì¸ ë¬¸ì„œ
```

---

## ğŸ§ª ê²€ì¦ ë° í…ŒìŠ¤íŠ¸

êµ¬í˜„ëœ ì»´í¬ë„ŒíŠ¸(Sampler, Loss, ProjectionHead)ê°€ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.

```bash
python scripts/test_triplet_components.py
```